{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape data gambar: (4190, 28, 28)\n",
      "Shape label: (4189,)\n",
      "Shape data gambar: (12570, 28, 28)\n",
      "Shape label: (4190,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "\n",
    "# Memuat dataset Fashion MNIST\n",
    "(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = fashion_mnist.load_data()\n",
    "\n",
    "# Memuat file CSV yang berisi label dari dataset FashionImages\n",
    "df = pd.read_csv('mytradataset/labels(1).csv')\n",
    "\n",
    "# Mengambil kolom 'articleType' sebagai label FashionImages\n",
    "fashionimage_labels = df.iloc[1:, 0]\n",
    "\n",
    "# Memilih hanya 4190 data pertama dari label FashionImage\n",
    "fashionimage_labels = fashionimage_labels[:4191].values\n",
    "\n",
    "# Menggabungkan label FashionImages dengan label MNIST\n",
    "merged_labels = np.concatenate([fashionimage_labels, np.zeros(len(train_labels_mnist[:4190])), np.zeros(len(test_labels_mnist[:4190]))], axis=0)\n",
    "\n",
    "# Menggabungkan gambar dari folder 'images' dengan dataset MNIST\n",
    "image_folder = 'mytradataset/images(1)/'\n",
    "image_data = []\n",
    "image_count = 0\n",
    "for filename in os.listdir(image_folder):\n",
    "    if image_count >= 4190:\n",
    "        break\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Mengubah gambar menjadi skala abu-abu (grayscale)\n",
    "    image = image.convert('L')\n",
    "    \n",
    "    # Menyesuaikan dimensi gambar menjadi 28x28\n",
    "    image = image.resize((28, 28))\n",
    "    \n",
    "    image_data.append(np.array(image))\n",
    "    image_count += 1\n",
    "\n",
    "# Konversi data gambar menjadi array numpy\n",
    "image_data_fashion = np.array(image_data)\n",
    "print(\"Shape data gambar:\", image_data_fashion.shape)\n",
    "print(\"Shape label:\", fashionimage_labels.shape)\n",
    "\n",
    "# Memastikan jumlah gambar dan label sama\n",
    "num_images = len(image_data_fashion)\n",
    "train_images_mnist = train_images_mnist[:num_images]\n",
    "test_images_mnist = test_images_mnist[:num_images]\n",
    "merged_labels = merged_labels[:num_images]\n",
    "\n",
    "# Menggabungkan data gambar dari FashionImage dan MNIST\n",
    "image_data = np.concatenate([image_data_fashion, train_images_mnist, test_images_mnist], axis=0)\n",
    "\n",
    "# Melihat shape data gambar dan label\n",
    "print(\"Shape data gambar:\", image_data.shape)\n",
    "print(\"Shape label:\", merged_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4190, 64190]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m merged_labels_encoded \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mfit_transform(merged_labels)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Membagi data menjadi train, validation, dan test sets\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m train_images, test_images, train_labels, test_labels \u001b[39m=\u001b[39m train_test_split(image_data, merged_labels_encoded, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m train_images, val_images, train_labels, val_labels \u001b[39m=\u001b[39m train_test_split(train_images, train_labels, test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# Normalisasi pixel intensitas gambar ke rentang 0-1\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rizky Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Rizky Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Rizky Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4190, 64190]"
     ]
    }
   ],
   "source": [
    "# Mengubah label menjadi tipe data 'str'\n",
    "merged_labels = merged_labels.astype(str)\n",
    "\n",
    "# Mengubah label menjadi one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "merged_labels_encoded = label_encoder.fit_transform(merged_labels)\n",
    "\n",
    "# Membagi data menjadi train, validation, dan test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(image_data, merged_labels_encoded, test_size=0.2, random_state=42)\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Normalisasi pixel intensitas gambar ke rentang 0-1\n",
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Mengubah dimensi gambar menjadi format yang sesuai untuk Conv2D\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "val_images = val_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
